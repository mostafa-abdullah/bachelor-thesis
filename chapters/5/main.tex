% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Evaluation and Future Work}\label{chapter:eval}
Having explained the encoding for the type system in Z3 and the type inference rules and the constraints generated by different Python constructs, we discuss here the experimentation we have done for the tool and discuss the current type inference limitations.

\section{Experimentation}
Testing the type inference is done by giving the tool a variety of programs, some of which focus on a single functionality (like multiple inheritance, function calls, etc.), while others are open source code gathered from different online open source platforms. However, all the open source projects that we use in our experimentation was not meant to be statically typed when it was written, so some parts of these projects oppose the restrictions imposed by having a nominal static type system for Python. An example of these parts is the following:

\begin{lstlisting}
class A:
	pass
	
class B(A):
	def f(self): ...

class C(A):
	def f(self): ...

def foo(x):
	x.f()
	
f(B())
f(C())
\end{lstlisting}

The type of the argument \lstinline|x| in function \lstinline|foo| is inferred to be of type \lstinline|A| (The super type of both \lstinline|B| and \lstinline|C|). However, class \lstinline|A| does not implement the method \lstinline|f|, so the call \lstinline|x.f()| in the body of \lstinline|foo| is invalid, although it will not fail at runtime. Accordingly, we had to modify some of the projects we used to fit the limitations imposed by having a static type system. After the types of these programs are inferred and the typed source code is generated, we run mypy \cite{mypy} to statically check these types and verify that the inference is correct.
\subsection{IMP Interpreter}
IMP \cite{imp} is a simple programming language developed in the 1970s. An interpreter for the language \cite{imp_i} was created by Jay Conrod as an example of building interpreters. This interpreter is an excellent testing material for our type inference for many reasons:

\begin{itemize}
	\item It does not violate any of the restrictions discussed in \ref{sub:st_ts_3}.
	\item It uses most of the Python patterns that we support, like intensive inheritance, callable objects, operator overloading and using built-in libraries.
	\item It is composed of more than 1000 lines of code, which is comparable to most Python projects.
\end{itemize}
The inference for this project runs in [...] seconds, which gives a prospect that the performance of the constraints solving is capable of handling a large portion of sized projects.

\section{Limitations}
Section \ref{sub:st_ts_3} states the restrictions imposed on the dynamic nature of Python by defining a static type inference for the language. We list here the limitations of the type inference and the programs it cannot currently infer types for.

\begin{enumerate}
\item Using reflective or introspective properties of Python is not supported.
\item Modifying global variables using \lstinline|global| keyword is not supported.
\item It is not possible to dynamically create and infer modules during runtime.
\item \lstinline|exec| and \lstinline|eval| commands are not supported.
\item It is not possible to define new function decorators, and using built-in decorators is currently limited to \lstinline|@staticmethod| and \lstinline|@abstractmethod| decorators.
\item Tuple assignments support only tuples not lists as assignment values. Similarly, list assignments support only lists and assignment values. For example, the following two assignments are not supported:
\begin{lstlisting}
a, b = [1, 2]  # Cannot assign list to tuple
[a, b] = 1, 2  # Cannot assign tuple to list
\end{lstlisting}
This limitation is put to decrease the number of generated constraints when any of such kind of assignments is encountered, and hence increase the inference performance.

\item \lstinline|super| call is not supported due to the reasons discussed in Section \ref{more_mult}.

\item Functions containing generic type variables and stub functions cannot be used as first class objects. They only support direct function calls.
\item Imported module via \lstinline|import| statement cannot be used as first class objects.

\item Classes in the whole program must have unique names even if they belong to different modules.
\end{enumerate}

\section{Future Work}
The current type inference is still in an elementary stage. The focus of this work was to provide a model for developing static type inference of dynamically typed languages. The goal was to define a static type system for Python and type inference rules that are sound in terms of static type checking. Having this goal achieved, our goal now is to make the type inference reliable for large-scale projects. We are faced with the challenge of supporting a larger subset of the Python programs. This opens multiple possibilities for future research. We present here some of the research and contributions to this tool that we encourage to be done in the future.

\subsection{Error Reporting}
Currently, if the generated constraints are unsatisfiable, the conflicting constraints are returned. However, the whole program is rejected in this case and no types are inferred. One possible future improvement is giving types to the program constructs except the ones contributing to the unsatisfiability of the constraints.
\subsection{Modularity}
The input program may be divided into independent components, such that a separate SMT problem is concerned with inferring the types of each component. So instead of having only one SMT solver and giving all the collected constraints to it, solving the SMT problem can be distributed across multiple solvers. This will lead to a significant improvement in the inference performance, and can also contribute to the error reporting discussed above. To have such modularity, advanced pre-analysis is required to determine the flow graph of the program, and divide the program components accordingly.
\subsection{Infer Built-in Types with Class Definition Rules}
The encoding presented in \ref{sec:builtin_enc} treats the encoding of most commonly used built-in types separately from the encoding of class definitions, although every type in Python comes down to a class definition. The reason for this encoding is that the number of constraints generated for inferring the class definitions is huge compared to the ones generated by handling the these built-in types separately. An interesting area of research in the future is applying the inference rules of the class definitions on these built-in types while maintaining fair performance. This will git rid of handling a lot of special case, and accordingly will make the type inference more natural with respect to the type system of Python. Also, this will lift some of the current type system restrictions, like inheriting from built-in types.
